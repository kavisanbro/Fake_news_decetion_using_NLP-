import nltk
import numpy as np
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Download NLTK stopwords if not already downloaded
nltk.download("stopwords")

# Load your preprocessed dataset into 'texts' and 'labels' lists
# texts = ['your preprocessed text data']
# labels = [0 or 1, where 0 represents real news and 1 represents fake news]

# Text preprocessing
stop_words = set(stopwords.words("english"))
tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words=stop_words)
tfidf_matrix = tfidf_vectorizer.fit_transform(texts)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    tfidf_matrix, labels, test_size=0.2, random_state=42
)

# Train a Multinomial Naive Bayes classifier
classifier = MultinomialNB()
classifier.fit(X_train, y_train)

# Make predictions
y_pred = classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print("Classification Report:\n", report)ï¿¼Enter
